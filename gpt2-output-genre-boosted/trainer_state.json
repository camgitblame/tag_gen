{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500.0,
  "global_step": 5055,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05,
      "grad_norm": 5.587568283081055,
      "learning_rate": 4.95351137487636e-05,
      "loss": 6.1353,
      "step": 50
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.6685404777526855,
      "learning_rate": 4.904055390702275e-05,
      "loss": 5.4975,
      "step": 100
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.6753172874450684,
      "learning_rate": 4.8555885262116717e-05,
      "loss": 4.849,
      "step": 150
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9637025594711304,
      "learning_rate": 4.806132542037587e-05,
      "loss": 4.5636,
      "step": 200
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.433837890625,
      "learning_rate": 4.756676557863502e-05,
      "loss": 4.3998,
      "step": 250
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7276248931884766,
      "learning_rate": 4.707220573689417e-05,
      "loss": 4.2791,
      "step": 300
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2432652711868286,
      "learning_rate": 4.657764589515332e-05,
      "loss": 4.2503,
      "step": 350
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.766274094581604,
      "learning_rate": 4.608308605341247e-05,
      "loss": 4.2403,
      "step": 400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9051379561424255,
      "learning_rate": 4.558852621167162e-05,
      "loss": 4.2174,
      "step": 450
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4537347555160522,
      "learning_rate": 4.509396636993076e-05,
      "loss": 4.1734,
      "step": 500
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.636533260345459,
      "learning_rate": 4.4599406528189913e-05,
      "loss": 4.1479,
      "step": 550
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0014837980270386,
      "learning_rate": 4.4104846686449064e-05,
      "loss": 4.1155,
      "step": 600
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4493162631988525,
      "learning_rate": 4.361028684470821e-05,
      "loss": 4.146,
      "step": 650
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8363764882087708,
      "learning_rate": 4.311572700296736e-05,
      "loss": 4.0947,
      "step": 700
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6013240814208984,
      "learning_rate": 4.262116716122651e-05,
      "loss": 4.1059,
      "step": 750
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.599036693572998,
      "learning_rate": 4.212660731948566e-05,
      "loss": 4.118,
      "step": 800
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7175689339637756,
      "learning_rate": 4.163204747774481e-05,
      "loss": 4.1202,
      "step": 850
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.8285319805145264,
      "learning_rate": 4.113748763600396e-05,
      "loss": 4.0955,
      "step": 900
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5687905550003052,
      "learning_rate": 4.064292779426311e-05,
      "loss": 4.1071,
      "step": 950
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6414371728897095,
      "learning_rate": 4.014836795252226e-05,
      "loss": 4.0582,
      "step": 1000
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6731883883476257,
      "learning_rate": 3.9653808110781405e-05,
      "loss": 4.0322,
      "step": 1050
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.7617617845535278,
      "learning_rate": 3.9159248269040555e-05,
      "loss": 4.0445,
      "step": 1100
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.5782301425933838,
      "learning_rate": 3.8664688427299705e-05,
      "loss": 4.0388,
      "step": 1150
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.5409716367721558,
      "learning_rate": 3.8170128585558856e-05,
      "loss": 4.0524,
      "step": 1200
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6087656617164612,
      "learning_rate": 3.7675568743818e-05,
      "loss": 4.0544,
      "step": 1250
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.6448609232902527,
      "learning_rate": 3.718100890207715e-05,
      "loss": 4.006,
      "step": 1300
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.5546897053718567,
      "learning_rate": 3.66864490603363e-05,
      "loss": 4.0483,
      "step": 1350
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.713562548160553,
      "learning_rate": 3.619188921859545e-05,
      "loss": 4.0471,
      "step": 1400
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.6356518268585205,
      "learning_rate": 3.56973293768546e-05,
      "loss": 4.0346,
      "step": 1450
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.71928471326828,
      "learning_rate": 3.520276953511375e-05,
      "loss": 3.9979,
      "step": 1500
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1471174955368042,
      "learning_rate": 3.47082096933729e-05,
      "loss": 4.0022,
      "step": 1550
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.901196300983429,
      "learning_rate": 3.421364985163205e-05,
      "loss": 4.0131,
      "step": 1600
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.7295495271682739,
      "learning_rate": 3.3719090009891196e-05,
      "loss": 4.004,
      "step": 1650
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8699268102645874,
      "learning_rate": 3.322453016815035e-05,
      "loss": 3.9544,
      "step": 1700
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.078657388687134,
      "learning_rate": 3.27299703264095e-05,
      "loss": 4.0028,
      "step": 1750
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.716499924659729,
      "learning_rate": 3.223541048466865e-05,
      "loss": 3.9794,
      "step": 1800
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2309650182724,
      "learning_rate": 3.174085064292779e-05,
      "loss": 4.011,
      "step": 1850
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6683591604232788,
      "learning_rate": 3.124629080118694e-05,
      "loss": 3.9969,
      "step": 1900
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.801206648349762,
      "learning_rate": 3.075173095944609e-05,
      "loss": 4.009,
      "step": 1950
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.6756467223167419,
      "learning_rate": 3.0257171117705246e-05,
      "loss": 4.0319,
      "step": 2000
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.6423299908638,
      "learning_rate": 2.976261127596439e-05,
      "loss": 3.9679,
      "step": 2050
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.9998571276664734,
      "learning_rate": 2.9268051434223544e-05,
      "loss": 3.9762,
      "step": 2100
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.6789846420288086,
      "learning_rate": 2.8773491592482694e-05,
      "loss": 3.9829,
      "step": 2150
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.9767199158668518,
      "learning_rate": 2.8278931750741845e-05,
      "loss": 4.0106,
      "step": 2200
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.526162326335907,
      "learning_rate": 2.778437190900099e-05,
      "loss": 3.9799,
      "step": 2250
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.093193769454956,
      "learning_rate": 2.728981206726014e-05,
      "loss": 3.9708,
      "step": 2300
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5920648574829102,
      "learning_rate": 2.679525222551929e-05,
      "loss": 3.9936,
      "step": 2350
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.9450991749763489,
      "learning_rate": 2.6300692383778436e-05,
      "loss": 3.9916,
      "step": 2400
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.6280068755149841,
      "learning_rate": 2.5806132542037587e-05,
      "loss": 3.9591,
      "step": 2450
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.684675395488739,
      "learning_rate": 2.5311572700296737e-05,
      "loss": 3.9502,
      "step": 2500
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.557343065738678,
      "learning_rate": 2.4817012858555884e-05,
      "loss": 3.9527,
      "step": 2550
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.972317099571228,
      "learning_rate": 2.4322453016815035e-05,
      "loss": 3.9932,
      "step": 2600
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.6112383008003235,
      "learning_rate": 2.3827893175074185e-05,
      "loss": 3.9595,
      "step": 2650
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.7026464343070984,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 3.9631,
      "step": 2700
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.6780756115913391,
      "learning_rate": 2.2838773491592483e-05,
      "loss": 3.9763,
      "step": 2750
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.986566960811615,
      "learning_rate": 2.2344213649851633e-05,
      "loss": 3.9469,
      "step": 2800
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.5125404596328735,
      "learning_rate": 2.184965380811078e-05,
      "loss": 3.9889,
      "step": 2850
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.774534285068512,
      "learning_rate": 2.135509396636993e-05,
      "loss": 3.9422,
      "step": 2900
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.6422765851020813,
      "learning_rate": 2.086053412462908e-05,
      "loss": 3.9572,
      "step": 2950
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.7371447086334229,
      "learning_rate": 2.0365974282888232e-05,
      "loss": 3.9823,
      "step": 3000
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.7226669192314148,
      "learning_rate": 1.987141444114738e-05,
      "loss": 3.9743,
      "step": 3050
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.6116533875465393,
      "learning_rate": 1.937685459940653e-05,
      "loss": 3.9652,
      "step": 3100
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.553573489189148,
      "learning_rate": 1.8882294757665676e-05,
      "loss": 3.9696,
      "step": 3150
    },
    {
      "epoch": 3.17,
      "grad_norm": 0.6465067267417908,
      "learning_rate": 1.838773491592483e-05,
      "loss": 3.9386,
      "step": 3200
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.6301271915435791,
      "learning_rate": 1.7893175074183977e-05,
      "loss": 3.9759,
      "step": 3250
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.6569342613220215,
      "learning_rate": 1.7398615232443128e-05,
      "loss": 3.9628,
      "step": 3300
    },
    {
      "epoch": 3.31,
      "grad_norm": 0.8009742498397827,
      "learning_rate": 1.6904055390702275e-05,
      "loss": 3.9478,
      "step": 3350
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.0871459245681763,
      "learning_rate": 1.6409495548961425e-05,
      "loss": 3.9504,
      "step": 3400
    },
    {
      "epoch": 3.41,
      "grad_norm": 0.5412428379058838,
      "learning_rate": 1.5914935707220572e-05,
      "loss": 3.9559,
      "step": 3450
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.1816954612731934,
      "learning_rate": 1.5420375865479726e-05,
      "loss": 3.9706,
      "step": 3500
    },
    {
      "epoch": 3.51,
      "grad_norm": 1.2212777137756348,
      "learning_rate": 1.4925816023738873e-05,
      "loss": 3.9498,
      "step": 3550
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.6039270162582397,
      "learning_rate": 1.4431256181998024e-05,
      "loss": 3.9539,
      "step": 3600
    },
    {
      "epoch": 3.61,
      "grad_norm": 0.7626168727874756,
      "learning_rate": 1.393669634025717e-05,
      "loss": 3.9488,
      "step": 3650
    },
    {
      "epoch": 3.66,
      "grad_norm": 0.6964802742004395,
      "learning_rate": 1.3442136498516323e-05,
      "loss": 3.9383,
      "step": 3700
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.6647524237632751,
      "learning_rate": 1.294757665677547e-05,
      "loss": 3.9503,
      "step": 3750
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.5867039561271667,
      "learning_rate": 1.2453016815034619e-05,
      "loss": 3.9655,
      "step": 3800
    },
    {
      "epoch": 3.81,
      "grad_norm": 0.6826198697090149,
      "learning_rate": 1.195845697329377e-05,
      "loss": 3.9589,
      "step": 3850
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.5269103050231934,
      "learning_rate": 1.1463897131552918e-05,
      "loss": 3.9381,
      "step": 3900
    },
    {
      "epoch": 3.91,
      "grad_norm": 0.6552532315254211,
      "learning_rate": 1.0969337289812068e-05,
      "loss": 3.9381,
      "step": 3950
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.6404169201850891,
      "learning_rate": 1.0474777448071217e-05,
      "loss": 3.9654,
      "step": 4000
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.6828264594078064,
      "learning_rate": 9.980217606330366e-06,
      "loss": 3.9817,
      "step": 4050
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.842858076095581,
      "learning_rate": 9.485657764589516e-06,
      "loss": 3.9348,
      "step": 4100
    },
    {
      "epoch": 4.1,
      "grad_norm": 0.6843017339706421,
      "learning_rate": 8.991097922848665e-06,
      "loss": 3.9767,
      "step": 4150
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.5788596868515015,
      "learning_rate": 8.496538081107814e-06,
      "loss": 3.957,
      "step": 4200
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.9210518002510071,
      "learning_rate": 8.001978239366964e-06,
      "loss": 3.9688,
      "step": 4250
    },
    {
      "epoch": 4.25,
      "grad_norm": 0.6727357506752014,
      "learning_rate": 7.507418397626113e-06,
      "loss": 3.9423,
      "step": 4300
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.6029645800590515,
      "learning_rate": 7.012858555885263e-06,
      "loss": 3.9183,
      "step": 4350
    },
    {
      "epoch": 4.35,
      "grad_norm": 0.6969637870788574,
      "learning_rate": 6.5182987141444125e-06,
      "loss": 3.9138,
      "step": 4400
    },
    {
      "epoch": 4.4,
      "grad_norm": 1.4962478876113892,
      "learning_rate": 6.02373887240356e-06,
      "loss": 3.9638,
      "step": 4450
    },
    {
      "epoch": 4.45,
      "grad_norm": 0.995024561882019,
      "learning_rate": 5.52917903066271e-06,
      "loss": 3.9285,
      "step": 4500
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.6436010599136353,
      "learning_rate": 5.03461918892186e-06,
      "loss": 3.9411,
      "step": 4550
    },
    {
      "epoch": 4.55,
      "grad_norm": 1.0703879594802856,
      "learning_rate": 4.540059347181009e-06,
      "loss": 3.9823,
      "step": 4600
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.558442234992981,
      "learning_rate": 4.045499505440158e-06,
      "loss": 3.9539,
      "step": 4650
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.8884738683700562,
      "learning_rate": 3.5509396636993076e-06,
      "loss": 3.9661,
      "step": 4700
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.6547081470489502,
      "learning_rate": 3.056379821958457e-06,
      "loss": 3.953,
      "step": 4750
    },
    {
      "epoch": 4.75,
      "grad_norm": 0.6394757628440857,
      "learning_rate": 2.5618199802176064e-06,
      "loss": 3.9259,
      "step": 4800
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.5927451848983765,
      "learning_rate": 2.0672601384767556e-06,
      "loss": 3.9422,
      "step": 4850
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.6602935791015625,
      "learning_rate": 1.5727002967359052e-06,
      "loss": 3.9406,
      "step": 4900
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.1021767854690552,
      "learning_rate": 1.0781404549950546e-06,
      "loss": 3.9726,
      "step": 4950
    },
    {
      "epoch": 4.95,
      "grad_norm": 0.7523682117462158,
      "learning_rate": 5.835806132542038e-07,
      "loss": 3.9361,
      "step": 5000
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.7284344434738159,
      "learning_rate": 8.902077151335312e-08,
      "loss": 3.9702,
      "step": 5050
    },
    {
      "epoch": 5.0,
      "step": 5055,
      "total_flos": 0.0,
      "train_loss": 4.0554772585483025,
      "train_runtime": 635.9291,
      "train_samples_per_second": 31.772,
      "train_steps_per_second": 7.949
    }
  ],
  "logging_steps": 50,
  "max_steps": 5055,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500.0,
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
